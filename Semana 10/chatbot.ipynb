{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jaime\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: ¡Hola! Soy un chatbot. Escribe 'adiós' para terminar la conversación.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaime\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaime\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "hola, ¿cómo estás?\n",
      "Chatbot: estoy bien, gracias.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import string  # Para procesar cadenas de texto\n",
    "\n",
    "# Descarga de recursos de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Texto de entrenamiento (puedes añadir más frases aquí)\n",
    "raw_text = \"\"\"\n",
    "Hola, ¿cómo estás?\n",
    "Estoy bien, gracias. ¿Cómo puedo ayudarte hoy?\n",
    "¿Cuál es tu nombre?\n",
    "Soy un chatbot simple.\n",
    "¿Qué puedes hacer?\n",
    "Puedo responder preguntas básicas.\n",
    "¿Dónde vives?\n",
    "Vivo en la nube.\n",
    "Gracias\n",
    "De nada, estoy aquí para ayudarte.\n",
    "Adiós\n",
    "¡Hasta luego!\n",
    "\"\"\"\n",
    "\n",
    "# Preprocesamiento del texto\n",
    "raw_text = raw_text.lower()  # Convertir a minúsculas\n",
    "sent_tokens = nltk.sent_tokenize(raw_text)  # Tokenización de oraciones\n",
    "word_tokens = nltk.word_tokenize(raw_text)  # Tokenización de palabras\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(str.maketrans('', '', string.punctuation))))\n",
    "\n",
    "# Función de respuesta\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "\n",
    "    if(req_tfidf == 0):\n",
    "        robo_response = robo_response + \"Lo siento, no te entendí.\"\n",
    "    else:\n",
    "        robo_response = robo_response + sent_tokens[idx]\n",
    "    sent_tokens.remove(user_response)\n",
    "    return robo_response\n",
    "\n",
    "# Chat en bucle\n",
    "flag = True\n",
    "print(\"Chatbot: ¡Hola! Soy un chatbot. Escribe 'adiós' para terminar la conversación.\")\n",
    "while(flag):\n",
    "    user_response = input().lower()\n",
    "    if(user_response not in ['adiós', 'hasta luego']):\n",
    "        if(user_response != 'gracias'):\n",
    "            print(\"Chatbot: \" + response(user_response))\n",
    "        else:\n",
    "            flag = False\n",
    "            print(\"Chatbot: De nada. ¡Cuídate!\")\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Chatbot: ¡Adiós!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
